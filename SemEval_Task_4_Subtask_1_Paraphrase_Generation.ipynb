{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Set up environment"
      ],
      "metadata": {
        "id": "IsQYcjMYRAFq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQZmQwiCAk0d"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U openai==0.28.1"
      ],
      "metadata": {
        "id": "L33zXNDWDXYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from enum import Enum\n",
        "from typing import Generic, TypeVar\n",
        "import torch\n",
        "import json\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import time\n",
        "from tqdm import tqdm as show_progress\n",
        "import io\n",
        "import openai\n",
        "import json\n",
        "from tqdm import tqdm\n"
      ],
      "metadata": {
        "id": "pM7MZoSEAnO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helper functions"
      ],
      "metadata": {
        "id": "Mc_WQ0kyRDxy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_json_file_with_data(output_file_path: str, data):\n",
        "    assert output_file_path.endswith('.json')\n",
        "    with open(output_file_path, 'w') as output_file:\n",
        "        json.dump(data, output_file, indent=2)"
      ],
      "metadata": {
        "id": "-UPk5FX5Okgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = 'your_key'"
      ],
      "metadata": {
        "id": "-ow8Aps4GL6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def paraphrase_text(query: str):\n",
        "    try:\n",
        "        result = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            n=3, #Specify how many needed\n",
        "            temperature=0.6,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are an English Professor\"},\n",
        "                {\"role\": \"user\", \"content\": query},\n",
        "            ],\n",
        "            request_timeout=30,  # Set your desired timeout value in seconds\n",
        "        )\n",
        "        return [result.choices[i].message.content for i in range(0, 3)]\n",
        "\n",
        "    except requests.exceptions.Timeout as e:\n",
        "        print(f\"Timeout occurred: {e}\")\n",
        "        return ['ERROR']\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return ['ERROR']"
      ],
      "metadata": {
        "id": "JcUzLbO6FquM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = paraphrase_text(\"Rephrase the sentence: Mr. President, we found a lot of funny memes about our invasion.  So, we're winning the information war?\")\n",
        "for i in range(0,len(prediction)):\n",
        "  print(i+1,\")\",prediction[i])"
      ],
      "metadata": {
        "id": "c8Hgx2bBGTUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the original JSON file\n",
        "with open('path_to_train_file', 'r') as file:\n",
        "    original_data = json.load(file)\n",
        "\n",
        "print(len(original_data))"
      ],
      "metadata": {
        "id": "4PYwaydqA4kD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate 'n' paraphrases"
      ],
      "metadata": {
        "id": "3QeFTFoHktbE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a list to store the new instances with paraphrased text\n",
        "new_instances = []\n",
        "\n",
        "# Use tqdm to add a progress bar\n",
        "for idx, instance in tqdm(enumerate(original_data), total=len((original_data), desc=\"Processing Instances\", unit=\"instance\"):\n",
        "    time.sleep(1.5)\n",
        "\n",
        "    # If we fail, try 2 more times\n",
        "    for _ in range(3):\n",
        "        try:\n",
        "            # Get the original text and other fields\n",
        "            original_text = instance.get('text', '')  # Default to an empty string if 'text' is not present\n",
        "            labels = instance.get('labels', [])  # Default to an empty list if 'labels' is not present\n",
        "            instance_id = instance.get('id', None)  # Default to None if 'id' is not present\n",
        "            link = instance.get('link', None)  # Default to None if 'link' is not present\n",
        "\n",
        "            # Paraphrase the text\n",
        "            query = \"Rephrase the sentence: \"\n",
        "            paraphrased_texts = paraphrase_text(query + original_text)\n",
        "\n",
        "            # Create new instances for each paraphrase\n",
        "            for i, paraphrased_text in enumerate(paraphrased_texts):\n",
        "                new_instance = {\n",
        "                    'instance_id': f\"{idx}_{i}\",  # Add an instance id with a suffix for each paraphrase\n",
        "                    'text': paraphrased_text,\n",
        "                    'labels': labels,  # Keep the original labels\n",
        "                    'id': instance_id,  # Keep the original id, or set to None if not present\n",
        "                    'link': link,  # Keep the original link, or set to None if not present\n",
        "                }\n",
        "\n",
        "                # Add the new instance to the list\n",
        "                new_instances.append(new_instance)\n",
        "\n",
        "            break\n",
        "\n",
        "        except Exception as e:\n",
        "            print(\"An error occurred.\")\n",
        "            print(e)\n",
        "            print(\"Waiting for 60 secs before trying again\")\n",
        "            time.sleep(60)\n",
        "            print(\"Trying again\")\n",
        "\n",
        "    # Storing intermediate results every 10 instances\n",
        "    if (idx % 10) == 0:\n",
        "        print(\"Storing intermediate results\")\n",
        "        create_json_file_with_data(\"path_to_result.json\", new_instances)\n",
        "\n",
        "# Save the new instances to a new JSON file\n",
        "create_json_file_with_data(\"path_to_result.json\", new_instances)\n",
        "print(\"Finished\")\n"
      ],
      "metadata": {
        "id": "vhldiV_JGRdj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ItpltlE75exn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}